{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision Recall Curves Pantograph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DataPantograph import DataPantograph\n",
    "from AsbestosModels import AsbestosModels\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set already exists. Loading the specified data ...\n",
      "\n",
      "Size of training set: 34\n",
      "\n",
      "Size of validation set: 3\n",
      "\n",
      "Size of test set: 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_data = \"./Both\"\n",
    "DA_parameters = {'path_name':path_data,\n",
    "                 'data_name':'Final_Report2',\n",
    "                 'size':(80,80),\n",
    "                 'data_augmentation':False,\n",
    "                 'train_percentage':0.63,\n",
    "                 'val_percentage':0.07,\n",
    "                 'test_percentage':0.3\n",
    "                 }\n",
    "# DP = DataPantograph('./Both','Final_Report',(128,128))\n",
    "DA = DataPantograph(**DA_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model number 0 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 1 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 2 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 3 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 4 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 5 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 6 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 7 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 1, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 8 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 150, 'S': 0}\n",
      "Model number 9 : PData_1Base_Train : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 10 : PData_1Hard_Examples BEST   : parameters {'MD': 2, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 2}\n",
      "Model number 11 : PData_1Hard_Examples  : parameters {'MD': 2, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 2}\n",
      "Model number 12 : PData_1Hard_ExamplesHE0 BEST   : parameters {'MD': 2, 'BV': 1, 'L': 3, 'BT': 10, 'D': 523, 'E': 70, 'S': 2}\n",
      "Model number 13 : PData_1Hard_ExamplesHE0  : parameters {'MD': 2, 'BV': 1, 'L': 3, 'BT': 10, 'D': 523, 'E': 70, 'S': 2}\n",
      "Model number 14 : PData_1Hard_ExamplesHE1  : parameters {'MD': 2, 'BV': 1, 'L': 3, 'BT': 10, 'D': 591, 'E': 70, 'S': 2}\n",
      "Model number 15 : PData_1HE2Base_Train BEST   : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 590, 'E': 150, 'S': 0}\n",
      "Model number 16 : PData_1HE2Base_Train  : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 590, 'E': 150, 'S': 0}\n",
      "Model number 17 : PData_1Only_Chip_Val : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 18 : PData_1Only_Chip_Val : parameters {'MD': 0, 'BV': 1, 'L': 1, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 19 : PData_1Only_Chip_Val : parameters {'MD': 0, 'BV': 1, 'L': 2, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "Model number 20 : PData_1Only_Chip_Val : parameters {'MD': 0, 'BV': 1, 'L': 3, 'BT': 10, 'D': 455, 'E': 70, 'S': 0}\n",
      "[<tf.Tensor 'input_1:0' shape=(?, ?, ?, 3) dtype=float32>, <tf.Tensor 'conv2d_2/Relu:0' shape=(?, ?, ?, 32) dtype=float32>, <tf.Tensor 'max_pooling2d_1/MaxPool:0' shape=(?, ?, ?, 32) dtype=float32>, <tf.Tensor 'conv2d_4/Relu:0' shape=(?, ?, ?, 64) dtype=float32>, <tf.Tensor 'max_pooling2d_2/MaxPool:0' shape=(?, ?, ?, 64) dtype=float32>, <tf.Tensor 'conv2d_6/Relu:0' shape=(?, ?, ?, 128) dtype=float32>, <tf.Tensor 'concatenate_1/concat:0' shape=(?, ?, ?, 192) dtype=float32>, <tf.Tensor 'conv2d_8/Relu:0' shape=(?, ?, ?, 64) dtype=float32>, <tf.Tensor 'concatenate_2/concat:0' shape=(?, ?, ?, 96) dtype=float32>, <tf.Tensor 'conv2d_10/Relu:0' shape=(?, ?, ?, 32) dtype=float32>, <tf.Tensor 'conv2d_11/Sigmoid:0' shape=(?, ?, ?, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "AM = AsbestosModels('./')\n",
    "model,model_name = AM.extract_model(0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32-BXLN2_20170210_060127_d_strip0_LargeROI.png',\n",
       " 'V_32-BXLN2_20170104_075859_b_Uitbrokkeling_strip0_LargeROI.png',\n",
       " 'V_32-BXLN2_20170209_155912_c_Uitbrokkeling_strip0_LargeROI.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA.val_names_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'input_12:0' shape=(?, ?, ?, 3) dtype=float32>, <tf.Tensor 'conv2d_103/Relu:0' shape=(?, ?, ?, 32) dtype=float32>, <tf.Tensor 'max_pooling2d_18/MaxPool:0' shape=(?, ?, ?, 32) dtype=float32>, <tf.Tensor 'conv2d_105/Relu:0' shape=(?, ?, ?, 64) dtype=float32>, <tf.Tensor 'concatenate_18/concat:0' shape=(?, ?, ?, 96) dtype=float32>, <tf.Tensor 'conv2d_107/Relu:0' shape=(?, ?, ?, 32) dtype=float32>, <tf.Tensor 'conv2d_108/Sigmoid:0' shape=(?, ?, ?, 1) dtype=float32>]\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20170220_111854_b_Uitbrokkeling_strip0_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 337 out of 337 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image V_32-BXLN2_20170104_085807_b_Uitbrokkeling_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 785 out of 785 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20170208_125814_b_Uitbrokkeling_strip0_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 263 out of 263 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "\t Analyzing fiber 1 ...\n",
      "\n",
      "\t 0 out of 390 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20170220_070253_b_Uitbrokkeling_strip0_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 1496 out of 1496 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "\t Analyzing fiber 1 ...\n",
      "\n",
      "\t 0 out of 594 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20170221_062056_b_Uitbrokkeling_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 239 out of 239 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "\t Analyzing fiber 1 ...\n",
      "\n",
      "\t 0 out of 382 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image 32-BXLN2_20170504_072300_b_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 411 out of 411 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "\t Analyzing fiber 1 ...\n",
      "\n",
      "\t 0 out of 204 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "\t Analyzing fiber 2 ...\n",
      "\n",
      "\t 0 out of 248 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "\t Analyzing fiber 3 ...\n",
      "\n",
      "\t 0 out of 589 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20170131_061927_b_Uitbrokkeling_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 113 out of 113 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "\t Analyzing fiber 1 ...\n",
      "\n",
      "\t 0 out of 116 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20170207_140051_b_Uitbrokkeling_strip0_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 340 out of 340 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image V_32-BXLN2_20161225_190741_b_Uitbrokkeling_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 1673 out of 1673 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image V_32-BXLN2_20161225_185715_b_Uitbrokkeling_strip0_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 1533 out of 1533 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20170129_140928_b_Uitbrokkeling_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 350 out of 350 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20161226_205808_b_Uitbrokkeling_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 540 out of 540 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image A_32-BXLN2_20161227_080042_c_Uitbrokkeling_strip0_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 166 out of 166 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image V_32-BXLN2_20161225_185715_b_Uitbrokkeling_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 842 out of 842 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "\t Analyzing fiber 1 ...\n",
      "\n",
      "\t 0 out of 458 pixels were found: 0%\n",
      "\n",
      "Fiber not found\n",
      "\n",
      "1\n",
      "(1, 256, 1600, 3)\n",
      "Analyzing image 32-BXLN2_20170202_080033_b_strip1_LargeROI.png ...\n",
      "\n",
      "\t Analyzing fiber 0 ...\n",
      "\n",
      "\t 96 out of 96 pixels were found: 100%\n",
      "\n",
      "Fiber found\n",
      "\n",
      "1\n",
      "|||||||||||||||||||||||||\n",
      "[[ 0.00310685  0.91555281  0.5         0.78333333]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-315c0f1f8447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|||||||||||||||||||||||||\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mf1_pix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mf1_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0maverage_total_measurements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import Asbestos_Utils as AU\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "percentage = 0.2\n",
    "threshold_range = np.array([0.992])\n",
    "names = DA.test_names_original\n",
    "path = DA.temp_test\n",
    "path_data = \"./Both\"\n",
    "for num_model in [19]:\n",
    "    model,model_name = AM.extract_model(num_model,3)\n",
    "    avg_precision_recall_parameters= {'names':names,\n",
    "                                      'path':path,\n",
    "                                      'threshold_range':threshold_range,\n",
    "                                      'percentage':percentage,\n",
    "                                      'model':model}\n",
    "    average_total_measurements = avg_precision_recall(**avg_precision_recall_parameters)\n",
    "    print(\"|||||||||||||||||||||||||\")\n",
    "    print(average_total_measurements)\n",
    "    f1_pix = average_total_measurements[0]*average_total_measurements[1]*2/(average_total_measurements[0]+average_total_measurements[1])\n",
    "    f1_obj = average_total_measurements[2]*average_total_measurements[3]*2/(average_total_measurements[2]+average_total_measurements[3])\n",
    "\n",
    "    print(\"||||||||||||||||||||||||\")\n",
    "    np.save('./Numpy Variables/'+'Test data '+'Percentage'+str(percentage).replace('.','_')+model_name,average_total_measurements)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00202761,  1.        ,  1.        ,  0.78333333]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_total_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_pix = average_total_measurements[0][0]*average_total_measurements[0][1]*2/(average_total_measurements[0][0]+average_total_measurements[0][1])\n",
    "f1_obj = average_total_measurements[0][2]*average_total_measurements[0][3]*2/(average_total_measurements[0][2]+average_total_measurements[0][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00404700582805 0.878504672897\n"
     ]
    }
   ],
   "source": [
    "print(f1_pix,f1_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "def avg_precision_recall(names,path,threshold_range,percentage,model):\n",
    "    total_measurements = np.zeros([len(threshold_range),4])\n",
    "    total_object_count = np.zeros([len(threshold_range),3]) \n",
    "    total_pixel_count = np.zeros([len(threshold_range),3])\n",
    "    for name in names:\n",
    "        image = cv2.imread(join(path,name))\n",
    "        label = cv2.imread(join(path,name.replace('.png','_FIB.png')),0)\n",
    "#         label = (AU.load_image(path_data,name.replace(AU.get_file_extension(name),'_FIB'+AU.get_file_extension(name)))).astype(np.uint8)\n",
    "        contour = get_contours(label)\n",
    "        prediction_parameters= {'name':name,\n",
    "                           'image':image,\n",
    "                           'label':label,\n",
    "                           'contours_label':contour,\n",
    "                           'model':model,\n",
    "                           'threshold_range':threshold_range,\n",
    "                           'percentage':percentage}\n",
    "        predictionObj = Prediction(**prediction_parameters)\n",
    "        total_pixel_count = total_pixel_count+predictionObj.pixel_count\n",
    "        total_object_count = total_object_count+predictionObj.object_count\n",
    "        total_measurements = total_measurements+predictionObj.measurements\n",
    "    average_total_measurements = total_measurements/len(names)\n",
    "    return average_total_measurements\n",
    "\n",
    "def get_contours(image, invert = True):\n",
    "    \"\"\"\n",
    "    A function that obtains the contours from an image\n",
    "    :return: A list with the contours for an image\n",
    "    \"\"\"\n",
    "    image = image.astype(np.uint8)\n",
    "    if invert:\n",
    "        __, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "        __, contours_per_image, __ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    else:\n",
    "        __, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "        __, contours_per_image, __ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    return contours_per_image\n",
    "class Prediction(object):\n",
    "    def __init__(self, name, image, label, contours_label, model, threshold_range, percentage):\n",
    "        self.name = name\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "        self.size = image.shape\n",
    "        self.contours_label = contours_label\n",
    "        self.total_fibers = len(contours_label)\n",
    "        self.model = model\n",
    "        self.threshold_range = threshold_range\n",
    "        self.percentage = percentage\n",
    "        prediction_model_unprocessed = self.prediction_model()\n",
    "        self.measurements = np.zeros([len(threshold_range),4])\n",
    "        self.pixel_count = np.zeros([len(threshold_range),3])\n",
    "        self.object_count = np.zeros([len(threshold_range),3])\n",
    "        for num_theta,theta in enumerate(threshold_range):\n",
    "            prediction_theta = self.post_processing(theta,prediction_model_unprocessed)\n",
    "            prediction_contours = get_contours(prediction_theta)\n",
    "            tp_pix,fp_pix,fn_pix,pixel_precision,pixel_recall = self.pixel_statistics(prediction_theta)\n",
    "            true_positive_objects,false_positive_objects,false_negative_objects = self.fiber_identification(prediction_contours)\n",
    "            object_precision,object_recall = self.object_statistics(true_positive_objects,false_positive_objects,false_negative_objects)\n",
    "            self.measurements[num_theta,0] = pixel_precision\n",
    "            self.measurements[num_theta,1] = pixel_recall\n",
    "            self.measurements[num_theta,2] = object_precision\n",
    "            self.measurements[num_theta,3] = object_recall\n",
    "            self.pixel_count[num_theta,0] = tp_pix\n",
    "            self.pixel_count[num_theta,1] = fp_pix\n",
    "            self.pixel_count[num_theta,2] = fn_pix\n",
    "            self.object_count[num_theta,0] = true_positive_objects\n",
    "            self.object_count[num_theta,1] = false_positive_objects\n",
    "            self.object_count[num_theta,2] = false_negative_objects\n",
    "            \n",
    "    def object_statistics(self,true_positive_objects,false_positive_objects,false_negative_objects):\n",
    "        try:\n",
    "            object_precision = true_positive_objects / (true_positive_objects + false_positive_objects)\n",
    "        except ZeroDivisionError:\n",
    "            object_precision = 0\n",
    "        try:\n",
    "            object_recall = true_positive_objects/(self.total_fibers)\n",
    "        except ZeroDivisionError:\n",
    "            object_recall = 0\n",
    "        return object_precision,object_recall\n",
    "\n",
    "    def fiber_identification(self,prediction_contours):\n",
    "        \"\"\"\n",
    "        Function that identifies the fibers in an image\n",
    "        :return: found_fibers(number) The amount of fibers found in the image\n",
    "        image_percentages(array) an array that includes the percentage found for each fiber\n",
    "        image_fiber_pixels(array) an array that includes the amount of pixels for each fiber\n",
    "        image_intersection_pixels(array) an array that includes the amount of pixels found for each fiber\n",
    "        \"\"\"\n",
    "        # Initialize the outputs\n",
    "        fiber_contours = get_contours(self.label)\n",
    "        found_fibers = 0\n",
    "        image_percentages = []\n",
    "        image_fiber_pixels = []\n",
    "        image_intersection_pixels = []\n",
    "        # Produce a mask for prediction comparizon\n",
    "        black_mask_prediction = np.zeros((self.size[0], self.size[1]))\n",
    "        black_mask_prediction = cv2.drawContours(black_mask_prediction, prediction_contours, -1, 255, -1)\n",
    "        print(\"Analyzing image %s ...\\n\" % self.name)\n",
    "        # Analyze whether each of the fibers in the image has been found and how much of the fiber was\n",
    "        # identified\n",
    "        for num_fiber, fiber in enumerate(fiber_contours):\n",
    "            print(\"\\t Analyzing fiber %d ...\\n\" % num_fiber)\n",
    "\n",
    "            found_fiber, percentage_found, intersection_pixels, fiber_pixels = self.fiber_discriminator(\n",
    "                fiber, black_mask_prediction)\n",
    "            # Remove the identified fiber from the prediction\n",
    "            black_mask_prediction = self.remove_fiber_from_prediction(fiber, black_mask_prediction)\n",
    "            # Include the results for each fiber in the overall output\n",
    "            found_fibers += found_fiber\n",
    "            image_intersection_pixels.append(intersection_pixels)\n",
    "            image_fiber_pixels.append(fiber_pixels)\n",
    "        false_positive_amount = self.false_positive_object_count(black_mask_prediction)\n",
    "        print(false_positive_amount)\n",
    "        false_negative_objects = len(fiber_contours)-found_fibers\n",
    "        return found_fibers, false_positive_amount,false_negative_objects\n",
    "\n",
    "    def false_positive_object_count(self,black_mask_prediction):\n",
    "        \"\"\"\n",
    "        Counts the number of false positive objects in the prediction\n",
    "        :param black_mask_prediction: The mask without the fiber predictions\n",
    "        :return: The number of false positive objects found\n",
    "        \"\"\"\n",
    "        false_positive_contours = get_contours(black_mask_prediction,invert = False)\n",
    "        return len(false_positive_contours)\n",
    "\n",
    "\n",
    "\n",
    "    def fiber_discriminator(self, fiber, black_mask_prediction):\n",
    "        \"\"\"\n",
    "        Function that takes the contours of a fiber and tells whether the fiber was identified by the prediction\n",
    "        with respect to certain percentage threshold.\n",
    "        :param fiber: Contour for the fiber\n",
    "        :param black_mask_prediction: Prediction mask to compare with\n",
    "        :return: found_fibers(number) Either 1 (found) or 0 (not found)\n",
    "        percentage_found Percentage of correctly identified pixels\n",
    "        fiber_pixels The amount of pixels for each fiber\n",
    "        intersection_pixels The amount of pixels found by the prediction for each fiber\n",
    "        \"\"\"\n",
    "        # Create a mask for the fiber\n",
    "        mask_label = np.zeros((self.size[0], self.size[1]))\n",
    "        mask_label = cv2.drawContours(mask_label, [fiber], -1, 255, -1)\n",
    "\n",
    "        fiber_pixels = int(np.sum(mask_label) / 255)  # Count of the fiber pixels\n",
    "        # Compare the fiber mask with the prediction\n",
    "        comparison = np.zeros((self.size[0], self.size[1]))\n",
    "        cv2.bitwise_and(mask_label, black_mask_prediction, comparison)\n",
    "        intersection_pixels = int(np.sum(comparison) / 255)  # Count pixels in the intersection\n",
    "        percentage_found = intersection_pixels / fiber_pixels  # Percentage of fiber pixels identified\n",
    "        print(\"\\t %d out of %d pixels were found: %d%%\\n\" % (\n",
    "        intersection_pixels, fiber_pixels, percentage_found * 100))\n",
    "        # Identify if a fiber was trully found\n",
    "        if percentage_found >= self.percentage:\n",
    "            found_fiber = 1\n",
    "            print(\"Fiber found\\n\")\n",
    "        else:\n",
    "            found_fiber = 0\n",
    "            print(\"Fiber not found\\n\")\n",
    "        # Remove the analyzed fiber pixels from the prediction (for False Positive purposes)\n",
    "\n",
    "        return found_fiber, percentage_found * 100, intersection_pixels, fiber_pixels\n",
    "\n",
    "    def remove_fiber_from_prediction(self, fiber, black_mask_prediction):\n",
    "        \"\"\"\n",
    "        This function removes from the prediction mask the pixels which predict certain fiber.\n",
    "        :param fiber: The fiber contour that will be removed from the prediction mask\n",
    "        :param black_mask_prediction: The prediction mask\n",
    "        :return: Returns the modified prediction mask without the selected fiber pixels.\n",
    "        \"\"\"\n",
    "        # Draw the fiber over the black prediction mask\n",
    "        black_mask_prediction = cv2.drawContours(black_mask_prediction, [fiber], -1, 255, -1)\n",
    "        # Create a fiber comparison mask\n",
    "        fiber_mask = np.zeros((self.size[0], self.size[1]))\n",
    "        fiber_mask = cv2.drawContours(fiber_mask, [fiber], -1, 255, -1)\n",
    "        # Get the contours of this new mask\n",
    "        new_contours = get_contours(black_mask_prediction,invert= False)\n",
    "        max_contour_intersection = 0 # Define an initial amount of pixels for the comparison\n",
    "        num_contour_removal = 0 # Choose the first new contour as the one that will be removed\n",
    "        comparison2 = np.zeros((self.size[0],self.size[1]))\n",
    "        for num_contour, contour in enumerate(new_contours):\n",
    "            # Create a mask for the comparison between the new contours and the fiber\n",
    "            black_mask_new = np.zeros((self.size[0], self.size[1]))\n",
    "            black_mask_new = cv2.drawContours(black_mask_new, [contour], -1, 255, -1)\n",
    "            intersection = np.sum(cv2.bitwise_and(black_mask_new, fiber_mask, comparison2))\n",
    "            if intersection > max_contour_intersection:\n",
    "                max_contour_intersection = intersection\n",
    "                num_contour_removal = num_contour\n",
    "        black_mask_prediction = cv2.drawContours(black_mask_prediction, new_contours, num_contour_removal, 0, -1)\n",
    "        return black_mask_prediction\n",
    "\n",
    "  \n",
    "    \n",
    "    def prediction_model(self):\n",
    "#         prediction_model_unprocessed = self.model.predict(self.image.reshape(1, self.size[0], self.size[1], 3)).reshape(self.size[0],self.size[1])\n",
    "        print(self.image[np.newaxis].shape)\n",
    "        prediction_model_unprocessed = model.predict(self.image[np.newaxis])\n",
    "        prediction_model_unprocessed = np.squeeze(prediction_model_unprocessed,axis = 0)\n",
    "        prediction_model_unprocessed = np.squeeze(prediction_model_unprocessed,axis = -1)\n",
    "        return prediction_model_unprocessed\n",
    "    \n",
    "    def post_processing(self,threshold,prediction_unprocessed):\n",
    "        prediction_bool_unprocessed = (prediction_unprocessed >= threshold)\n",
    "        prediction_grayscale = prediction_bool_unprocessed * 255\n",
    "        prediction_processed = self.remove_trash(prediction_grayscale)\n",
    "        return prediction_processed\n",
    "    \n",
    "        \n",
    "\n",
    "    def remove_trash(self, prediction_unprocessed):\n",
    "        \"\"\"\n",
    "        This function takes a prediction along with its contours and returns an image without small isolated pixels\n",
    "        :return: ndarray with the prediction striped out of small isolated pixels\n",
    "        \"\"\"\n",
    "        contours_preprocessed = get_contours(prediction_unprocessed)\n",
    "        for num_contour, contour in enumerate(contours_preprocessed):\n",
    "            if int(cv2.contourArea(contour)) <= 18:\n",
    "                prediction_unprocessed = cv2.drawContours(prediction_unprocessed, [contour], -1, 255, -1)\n",
    "        prediction_processed = prediction_unprocessed\n",
    "        return prediction_processed\n",
    "\n",
    "    def pixel_statistics(self,prediction_theta):\n",
    "        \"\"\"\n",
    "        The input is a prediction image and a labeled image. The image matrices should be 0 where there is a fiber\n",
    "        :param prediction: Image prediction with 0 if there is a fiber (can be boolean or not as long as this requirement is added)\n",
    "        :return: Pixel values for TP,FP,FN. Precision and recall for the prediction is also returned.\n",
    "        \"\"\"\n",
    "        tp_mask = np.logical_not((prediction_theta == 0) * (self.label == 0)) * 1\n",
    "        fp_mask = np.logical_not((prediction_theta == 0) * (self.label != 0)) * 1\n",
    "        fn_mask = np.logical_not((prediction_theta != 0) * (self.label == 0)) * 1\n",
    "        tp_pix = np.sum(np.logical_not(tp_mask))\n",
    "        fp_pix = np.sum(np.logical_not(fp_mask))\n",
    "        fn_pix = np.sum(np.logical_not(fn_mask))\n",
    "        try:\n",
    "            pixel_precision = tp_pix / (tp_pix + fp_pix)\n",
    "        except ZeroDivisionError:\n",
    "            pixel_precision = 0\n",
    "        try:\n",
    "            pixel_recall = tp_pix / (tp_pix + fn_pix)\n",
    "        except ZeroDivisionError:\n",
    "            pixel_recall = 0\n",
    "        return tp_pix,fp_pix,fn_pix,pixel_precision, pixel_recall\n",
    "    \n",
    "    \n",
    "def save_plots(average_total_measurements,model_name):\n",
    "    # Plot pix precision-recall\n",
    "    plt.plot(average_total_measurements[:,1],average_total_measurements[:,0],'-x',linewidth = 3.0)\n",
    "    plt.xlabel(\"Average Recall\")\n",
    "    plt.ylabel(\"Average Precision\")\n",
    "    plt.grid()\n",
    "    plt.savefig('PR plots/PR pix/'+'PR_PIX_'+model_name+'.png')\n",
    "    plt.clf()\n",
    "    # Plot object precision-recall\n",
    "    plt.plot(average_total_measurements[:,3],average_total_measurements[:,2],'-x',linewidth = 3.0)\n",
    "    plt.xlabel(\"Average Recall\")\n",
    "    plt.ylabel(\"Average Precision\")\n",
    "    plt.grid()\n",
    "    plt.savefig('PR plots/PR object/'+'PR_OBJ_'+model_name+'.png')\n",
    "    plt.clf()\n",
    "    # Plot F-score\n",
    "    f_score_pix = 2*np.divide(np.multiply(average_total_measurements[:,0],average_total_measurements[:,1]),average_total_measurements[:,0]+average_total_measurements[:,1])\n",
    "    plt.plot(average_total_measurements[:,1],f_score_pix,'-x')\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.xlabel(\"Average Recall\")\n",
    "    plt.grid()\n",
    "    plt.savefig('PR plots/F1/'+'F1_'+model_name+'.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
